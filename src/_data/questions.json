{
  "questions": [
    {
      "id": "mcq_001",
      "questionText": "A forecaster uses past inflation and interest rates to predict next quarter’s inflation and tunes the model to minimize out-of-sample error. What is the primary goal?",
      "options": [
        "Causal inference",
        "Prediction",
        "Policy evaluation",
        "Hypothesis testing"
      ],
      "correctAnswer": "Prediction",
      "difficulty": "easy",
      "topic": "Lecture 1 – Prediction vs Causation",
      "explanation": "Prediction prioritizes minimizing forecast error on unseen data; causal inference would focus on identifying an unbiased effect of a treatment under assumptions about $E[u|X]$."
    },
    {
      "id": "mcq_002",
      "questionText": "A survey samples different households in 2018 and a new independent sample in 2024 (no tracking of the same households). What type of data is this?",
      "options": [
        "Cross-sectional data",
        "Time series data",
        "Pooled cross-sections",
        "Panel (longitudinal) data"
      ],
      "correctAnswer": "Pooled cross-sections",
      "difficulty": "medium",
      "topic": "Lecture 1 – Data Types",
      "explanation": "Two independent cross-sections combined over time form pooled cross-sections. Panel data would track the **same** units across years; time series is one variable over time."
    },
    {
      "id": "mcq_003",
      "questionText": "In the OLS model y = b0 + b1 x + u, which sample property holds by the first-order conditions?",
      "options": [
        "Residuals are uncorrelated with $x$",
        "Residuals are normally distributed",
        "Residual variance is constant",
        "Residuals sum to the mean of $y$"
      ],
      "correctAnswer": "Residuals are uncorrelated with $x$",
      "difficulty": "medium",
      "topic": "Lecture 1 – OLS Properties",
      "explanation": "The OLS normal equations imply $\\sum \\hat u_i x_i=0$ and $\\sum \\hat u_i=0$ (with an intercept). Normality and homoskedasticity are **not** implied by OLS."
    },
    {
      "id": "mcq_004",
      "questionText": "A simple regression of CEO salary on profits yields R^2 = 0.09. Correct interpretation?",
      "options": [
        "9% chance the relation is causal",
        "9% of the variation in salary is explained by profits",
        "Salary rises 9% for each €1 profit",
        "The slope is biased by 9%"
      ],
      "correctAnswer": "9% of the variation in salary is explained by profits",
      "difficulty": "easy",
      "topic": "Lecture 1 – Model Fit",
      "explanation": "$R^2$ is the fraction of sample variance in $y$ explained by regressors. It says **nothing** about causality or the size of the slope."
    },
    {
      "id": "mcq_005",
      "questionText": "Log–log model: log(Sales) = 3.8 + 0.45 log(AdSpend). Interpretation of 0.45?",
      "options": [
        "€1 more AdSpend raises sales by 0.45 units",
        "1% more AdSpend is associated with 0.45% more sales",
        "1% more AdSpend raises sales by 0.45 units",
        "Elasticity of log-sales w.r.t. AdSpend in euros"
      ],
      "correctAnswer": "1% more AdSpend is associated with 0.45% more sales",
      "difficulty": "easy",
      "topic": "Lecture 1 – Functional Forms",
      "explanation": "In a log–log model, the slope is an elasticity: $\\partial\\ln y/\\partial\\ln x=0.45$, so a 1% change in $x$ relates to ~0.45% change in $y$."
    },
    {
      "id": "mcq_006",
      "questionText": "Log–level model: log(y) = a + b x with b = 0.08. Best interpretation?",
      "options": [
        "A one-unit increase in $x$ changes $y$ by 0.08 units",
        "A one-unit increase in $x$ is associated with an 8% increase in $y$",
        "A 1% increase in $x$ raises $y$ by 0.08%",
        "A one-unit increase in $x$ is associated with a 0.08% increase in $y$"
      ],
      "correctAnswer": "A one-unit increase in $x$ is associated with an 8% increase in $y$",
      "difficulty": "medium",
      "topic": "Lecture 1 – Functional Forms",
      "explanation": "For log–level: $\\partial\\ln y/\\partial x=b\\Rightarrow$ a one-unit rise in $x$ changes $y$ by approximately $100\\times b=8\\%$."
    },
    {
      "id": "mcq_007",
      "questionText": "Wage on Education omits Ability. Ability is positively correlated with Education and positively affects Wage. Direction of bias on Education?",
      "options": [
        "Upward bias",
        "Downward bias",
        "No bias",
        "Cannot be determined"
      ],
      "correctAnswer": "Upward bias",
      "difficulty": "hard",
      "topic": "Lecture 2 – Omitted Variable Bias",
      "explanation": "OVB sign is $\\operatorname{sign}(\\beta_Z)\\times\\operatorname{sign}(\\operatorname{Cov}(X,Z))$. Here both are positive $\\Rightarrow$ upward bias on education."
    },
    {
      "id": "mcq_008",
      "questionText": "Which is a bad control when estimating the effect of education on wages?",
      "options": [
        "Years of experience (confounder)",
        "Innate ability (confounder)",
        "Current occupation if partly determined by education (mediator)",
        "Age in years"
      ],
      "correctAnswer": "Current occupation if partly determined by education (mediator)",
      "difficulty": "medium",
      "topic": "Lecture 2 – Good vs Bad Controls",
      "explanation": "Controlling for a mediator (on the causal path from education to wage) blocks part of the causal effect and biases estimates."
    },
    {
      "id": "mcq_009",
      "questionText": "Which change generally makes the OLS slope more precise?",
      "options": [
        "Reduce sample size",
        "Increase error variance",
        "Decrease variance of x",
        "Increase variance of x"
      ],
      "correctAnswer": "Increase variance of x",
      "difficulty": "medium",
      "topic": "Lecture 2 – Precision of OLS",
      "explanation": "$\\operatorname{Var}(\\hat\\beta_1)$ decreases with larger variation in $x$ and larger $n$, but increases with error variance."
    },
    {
      "id": "mcq_010",
      "questionText": "In y = b0 + b1 x1 + b2 x2 + u, b1 measures:",
      "options": [
        "Total effect of $x_1$ ignoring $x_2$",
        "Correlation of $x_1$ and $y$",
        "Effect of $x_1$ on $y$ holding $x_2$ constant",
        "Average of $y$ when $x_1=1$"
      ],
      "correctAnswer": "Effect of $x_1$ on $y$ holding $x_2$ constant",
      "difficulty": "easy",
      "topic": "Lecture 2 – Interpretation",
      "explanation": "$b_1$ is a ceteris paribus effect: partial derivative $\\partial y/\\partial x_1$ given $x_2$."
    },
    {
      "id": "mcq_011",
      "questionText": "To test that several coefficients are jointly zero, use:",
      "options": [
        "t-test",
        "F-test",
        "Durbin–Watson test",
        "Breusch–Pagan test"
      ],
      "correctAnswer": "F-test",
      "difficulty": "easy",
      "topic": "Lecture 2 – Hypothesis Testing",
      "explanation": "The F-test handles multiple linear restrictions $H_0: R\\beta=r$. A t-test applies to a single linear restriction."
    },
    {
      "id": "mcq_012",
      "questionText": "Which is a symptom of high (but not perfect) multicollinearity?",
      "options": [
        "Large standard errors and unstable coefficient signs across similar specifications",
        "Biased OLS coefficients",
        "Lower R^2",
        "Biased intercept only"
      ],
      "correctAnswer": "Large standard errors and unstable coefficient signs across similar specifications",
      "difficulty": "medium",
      "topic": "Lecture 2 – Multicollinearity",
      "explanation": "Multicollinearity inflates variances of coefficients (unstable estimates). It does not create bias in OLS under exogeneity. Near collinearity inflates $\\operatorname{Var}(\\hat{\\beta})$ and makes signs sensitive; it does not bias OLS if $E[u|X]=0$."
    },
    {
      "id": "mcq_013",
      "questionText": "Dummy/interactions model: Wage = b0 + b1 Female + b2 Educ + b3(Female×Educ) + u. What does b3 measure?",
      "options": [
        "Wage gap at zero education",
        "Return to education for females",
        "Difference in returns to education between females and males",
        "Return to education for males"
      ],
      "correctAnswer": "Difference in returns to education between females and males",
      "difficulty": "medium",
      "topic": "Lecture 2 – Interactions and Dummies",
      "explanation": "$b_3$ is the interaction slope difference: $\\partial\\text{Wage}/\\partial\\text{Educ}$ for females minus that for males."
    },
    {
      "id": "mcq_014",
      "questionText": "Adjusted R^2 compared to R^2:",
      "options": [
        "Always increases when adding regressors",
        "Penalizes extra regressors and can fall when adding irrelevant variables",
        "Ignores sample size",
        "Is numerically identical to AIC"
      ],
      "correctAnswer": "Penalizes extra regressors and can fall when adding irrelevant variables",
      "difficulty": "medium",
      "topic": "Lecture 2 – Model Fit",
      "explanation": "$R^2_{adj}=1-(1-R^2)\\frac{n-1}{n-k-1}$ can decrease if added regressors do not improve fit enough to offset the penalty."
    },
    {
      "id": "mcq_015",
      "questionText": "AIC vs BIC: typically, BIC:",
      "options": [
        "Penalizes less and selects larger models",
        "Penalizes more and selects simpler models",
        "Ignores likelihood",
        "Equals adjusted $R^2$"
      ],
      "correctAnswer": "Penalizes more and selects simpler models",
      "difficulty": "medium",
      "topic": "Lecture 3 – Model Selection",
      "explanation": "BIC penalty is $k\\ln n$ (larger than AIC’s $2k$ for $n\\ge 8$), so it favors more parsimonious models."
    },
    {
      "id": "mcq_016",
      "questionText": "A time series is covariance stationary if:",
      "options": [
        "Mean, variance, and autocovariance are time-invariant",
        "Mean and variance are zero",
        "It has a deterministic trend only",
        "Its autocorrelations are all zero"
      ],
      "correctAnswer": "Mean, variance, and autocovariance are time-invariant",
      "difficulty": "medium",
      "topic": "Lecture 3 – Stationarity",
      "explanation": "Weak stationarity requires constant $E(Y_t)$, constant $\\operatorname{Var}(Y_t)$, and $\\operatorname{Cov}(Y_t,Y_{t-k})$ depending only on $k$."
    },
    {
      "id": "mcq_017",
      "questionText": "ADF test is primarily used to:",
      "options": [
        "Detect serial correlation in residuals",
        "Test for a unit root",
        "Test for heteroskedasticity",
        "Select lag length"
      ],
      "correctAnswer": "Test for a unit root",
      "difficulty": "medium",
      "topic": "Lecture 3 – Unit Root Tests",
      "explanation": "ADF tests $H_0: \\gamma=0$ in $\\Delta y_t=\\alpha+\\beta t+\\gamma y_{t-1}+\\sum\\delta_i\\Delta y_{t-i}+\\varepsilon_t$; $H_0$ implies a unit root."
    },
    {
      "id": "mcq_018",
      "questionText": "Regressing two unrelated trending series on each other with high R^2 indicates:",
      "options": [
        "Omitted variable bias",
        "Spurious regression",
        "Measurement error",
        "Perfect multicollinearity"
      ],
      "correctAnswer": "Spurious regression",
      "difficulty": "medium",
      "topic": "Lecture 3 – Spurious Regression",
      "explanation": "Non-stationary series with trends can yield high $R^2$ and significant $t$-stats even without any true relationship."
    },
    {
      "id": "mcq_019",
      "questionText": "In AR(1): Y_t = a + r Y_{t-1} + u_t, |r|=1 implies:",
      "options": [
        "Stationary mean reversion",
        "Explosive series",
        "Random walk (non-stationary)",
        "White noise"
      ],
      "correctAnswer": "Random walk (non-stationary)",
      "difficulty": "medium",
      "topic": "Lecture 3 – AR(1)",
      "explanation": "When $|r|=1$, the process has a unit root; shocks are permanent and the variance grows with $t$."
    },
    {
      "id": "mcq_020",
      "questionText": "White noise errors u_t are characterized by:",
      "options": [
        "Nonzero mean and no autocorrelation",
        "Zero mean, constant variance, no autocorrelation",
        "Time-varying variance and autocorrelation",
        "Strong seasonality"
      ],
      "correctAnswer": "Zero mean, constant variance, no autocorrelation",
      "difficulty": "easy",
      "topic": "Lecture 3 – White Noise",
      "explanation": "White noise: $E(u_t)=0$, $\\operatorname{Var}(u_t)=\\sigma^2$, and $\\operatorname{Cov}(u_t,u_s)=0$ for $t\\ne s$."
    },
    {
      "id": "mcq_021",
      "questionText": "A correlogram (ACF plot) shows bars outside confidence bands at low lags. This suggests:",
      "options": [
        "No persistence",
        "Statistically significant autocorrelation at those lags",
        "Heteroskedasticity",
        "A unit root is certain"
      ],
      "correctAnswer": "Statistically significant autocorrelation at those lags",
      "difficulty": "medium",
      "topic": "Lecture 3 – ACF/Correlogram",
      "explanation": "Bars beyond the confidence bands indicate $\\rho_k\\ne 0$ at those lags; this signals serial dependence."
    },
    {
      "id": "mcq_022",
      "questionText": "Breusch–Godfrey test is used to detect:",
      "options": [
        "Heteroskedasticity",
        "Serial correlation up to order p in residuals",
        "Unit roots in Y",
        "Nonlinearity"
      ],
      "correctAnswer": "Serial correlation up to order p in residuals",
      "difficulty": "medium",
      "topic": "Lecture 3 – Diagnostics",
      "explanation": "BG tests $H_0:$ no AR($p$) in residuals by regressing residuals on original regressors and lagged residuals."
    },
    {
      "id": "mcq_023",
      "questionText": "In an MA(q) model, for horizon h > q, forecasts tend to:",
      "options": [
        "Explode",
        "Follow the last value",
        "Revert to the process mean",
        "Oscillate randomly around zero with growing variance"
      ],
      "correctAnswer": "Revert to the process mean",
      "difficulty": "medium",
      "topic": "Lecture 3 – Forecasting",
      "explanation": "Future MA shocks beyond horizon $q$ have zero conditional mean, so forecasts converge to $\\mu$."
    },
    {
      "id": "mcq_024",
      "questionText": "In an ARDL(p,q) model, the long-run multiplier for X represents:",
      "options": [
        "Immediate impact of X on Y",
        "Total equilibrium change in Y after a permanent change in X",
        "Persistence of Y via AR terms",
        "Average short-run effect"
      ],
      "correctAnswer": "Total equilibrium change in Y after a permanent change in X",
      "difficulty": "medium",
      "topic": "Lecture 3 – ARDL",
      "explanation": "LRM $=\\frac{\\sum_{j=0}^q \\beta_j}{1-\\sum_{i=1}^p \\phi_i}$ gives the total long-run response after full adjustment."
    },
    {
      "id": "mcq_025",
      "questionText": "Comparing two forecasting models using RMSE, a lower RMSE indicates:",
      "options": [
        "Better in-sample fit necessarily",
        "Smaller average forecast error magnitude",
        "Lower bias but higher variance",
        "Greater parsimony"
      ],
      "correctAnswer": "Smaller average forecast error magnitude",
      "difficulty": "easy",
      "topic": "Lecture 3 – Forecast Evaluation",
      "explanation": "RMSE $=\\sqrt{\\frac{1}{n}\\sum e_t^2}$; lower RMSE means, on average, smaller squared errors out of sample (not necessarily better in-sample fit)."
    },
    {
      "id": "mcq_026",
      "questionText": "Including a linear time trend t in a regression primarily captures:",
      "options": [
        "Short-run fluctuations",
        "Long-run deterministic growth/decline",
        "Seasonal effects",
        "Autocorrelated errors"
      ],
      "correctAnswer": "Long-run deterministic growth/decline",
      "difficulty": "medium",
      "topic": "Lecture 3 – Time Trends",
      "explanation": "A linear trend $t$ absorbs smooth long-run drift in $y_t$; seasonal dummies handle seasonality; AR terms handle autocorrelation."
    },
    {
      "id": "mcq_027",
      "questionText": "Fixed Effects (Within) estimator removes unobserved time-invariant heterogeneity by:",
      "options": [
        "Differencing adjacent periods",
        "Subtracting each individual’s time mean",
        "Adding only time dummies",
        "Using cross-sectional averages"
      ],
      "correctAnswer": "Subtracting each individual’s time mean",
      "difficulty": "easy",
      "topic": "Lecture 4 – Fixed Effects",
      "explanation": "Within transformation: $y_{it}-\\bar y_i$ and $x_{it}-\\bar x_i$ wipe out individual fixed effects $\\alpha_i$."
    },
    {
      "id": "mcq_028",
      "questionText": "Which coefficient cannot be identified in a standard Fixed Effects model?",
      "options": [
        "A time-invariant characteristic (e.g., gender) for an individual",
        "A time-varying policy indicator",
        "Lagged dependent variable",
        "Time dummies"
      ],
      "correctAnswer": "A time-invariant characteristic (e.g., gender) for an individual",
      "difficulty": "easy",
      "topic": "Lecture 4 – FE Limitations",
      "explanation": "Time-invariant regressors are collinear with unit fixed effects and drop out after within transformation."
    },
    {
      "id": "mcq_029",
      "questionText": "Strict exogeneity in panels requires that regressors are uncorrelated with:",
      "options": [
        "Only current errors",
        "Past and current errors",
        "All past, current, and future idiosyncratic errors",
        "Only future errors"
      ],
      "correctAnswer": "All past, current, and future idiosyncratic errors",
      "difficulty": "hard",
      "topic": "Lecture 4 – Exogeneity",
      "explanation": "Strict exogeneity: $E(u_{it}|X_i)=0$ for all $t$, ruling out feedback from past $u$ to future $x$ and from future $u$ to current $x$."
    },
    {
      "id": "mcq_030",
      "questionText": "FE vs First Differences: FD is preferred over FE when idiosyncratic errors:",
      "options": [
        "Are serially uncorrelated (white noise)",
        "Follow a random walk",
        "Are homoskedastic",
        "Are independent across individuals"
      ],
      "correctAnswer": "Follow a random walk",
      "difficulty": "hard",
      "topic": "Lecture 4 – FE vs FD",
      "explanation": "When $u_{it}$ is highly persistent (e.g., AR(1) near 1), first differencing can better remove it; FE is more efficient if $u_{it}$ is white noise."
    },
    {
      "id": "mcq_031",
      "questionText": "A balanced panel means:",
      "options": [
        "All individuals observed for all time periods",
        "No missing variables",
        "Equal numbers of individuals and periods",
        "Identical values of regressors across time"
      ],
      "correctAnswer": "All individuals observed for all time periods",
      "difficulty": "easy",
      "topic": "Lecture 4 – Panel Structure",
      "explanation": "Balanced: every unit has $T$ observations. Unbalanced panels allow different $T_i$."
    },
    {
      "id": "mcq_032",
      "questionText": "Within vs Between variation: Fixed Effects estimates rely primarily on:",
      "options": [
        "Between-individual differences only",
        "Within-individual changes over time",
        "Cross-sectional averages",
        "Time dummies only"
      ],
      "correctAnswer": "Within-individual changes over time",
      "difficulty": "easy",
      "topic": "Lecture 4 – Within vs Between",
      "explanation": "FE identifies effects from deviations around each unit’s mean (within variation), not from between-unit differences."
    },
    {
      "id": "mcq_101",
      "questionText": "Which statement best distinguishes prediction from causal inference in econometrics?",
      "options": [
        "Prediction requires randomized experiments; causation does not",
        "Prediction optimizes forecast accuracy; causal inference seeks unbiased effect estimates",
        "Causal inference ignores identification; prediction focuses on it",
        "Both require the same assumptions"
      ],
      "correctAnswer": "Prediction optimizes forecast accuracy; causal inference seeks unbiased effect estimates",
      "difficulty": "easy",
      "topic": "Lecture 1 – Prediction vs Causation",
      "explanation": "Prediction targets low out-of-sample loss; causal inference targets identification under assumptions (e.g., conditional independence). Randomization aids causality, not prediction per se."
    },
    {
      "id": "mcq_102",
      "questionText": "Which dataset is time series data?",
      "options": [
        "500 households in 2024",
        "Monthly CPI for the Netherlands, 2010–2025",
        "Graduates surveyed in 2018 and a new sample in 2024",
        "2,000 firms tracked annually from 2015–2025"
      ],
      "correctAnswer": "Monthly CPI for the Netherlands, 2010–2025",
      "difficulty": "easy",
      "topic": "Lecture 1 – Data Types",
      "explanation": "Time series: repeated measures on the **same variable** over time. Panels track the same units; pooled cross-sections change units across waves."
    },
    {
      "id": "mcq_103",
      "questionText": "In simple OLS, which is guaranteed by the normal equations?",
      "options": [
        "Residuals sum to zero",
        "Residuals are homoskedastic",
        "Residuals are independent and identically distributed",
        "Regressors are exogenous"
      ],
      "correctAnswer": "Residuals sum to zero",
      "difficulty": "easy",
      "topic": "Lecture 1 – OLS Properties",
      "explanation": "With an intercept, $\\sum_i \\hat u_i = 0$ exactly. Exogeneity and homoskedasticity are assumptions, not outcomes of OLS."
    },
    {
      "id": "mcq_104",
      "questionText": "Level–log model: y = a + b log(x). If b = 2.5, a 1% increase in x is associated with:",
      "options": [
        "A 2.5% increase in y",
        "A 0.025 increase in y",
        "A 0.25 increase in y",
        "A 2.5 unit increase in y"
      ],
      "correctAnswer": "A 0.025 increase in y",
      "difficulty": "medium",
      "topic": "Lecture 1 – Functional Forms",
      "explanation": "Level–log: $\\partial y/\\partial\\ln x=b$. A 1% change in $x$ is $\\Delta\\ln x\\approx 0.01$, so $\\Delta y\\approx b\\times0.01=0.025$."
    },
    {
      "id": "mcq_105",
      "questionText": "Omitted variable bias: X (education) is negatively correlated with the omitted variable Z (local unemployment risk), and Z positively affects Y (wages). Direction of bias on education?",
      "options": [
        "Upward",
        "Downward",
        "Zero",
        "Ambiguous"
      ],
      "correctAnswer": "Downward",
      "difficulty": "medium",
      "topic": "Lecture 2 – OVB Direction",
      "explanation": "Bias sign is $\\operatorname{sign}(\\beta_Z)\\times\\operatorname{sign}(\\operatorname{Cov}(X,Z))= (+)\\times(-)= -$ (downward)."
    },
    {
      "id": "mcq_107",
      "questionText": "In a model with k restrictions tested jointly, which statement is correct?",
      "options": [
        "For k=1, the F-test equals the squared t-test",
        "For any k, the F-test equals the squared t-test",
        "The F-test cannot be used when k=1",
        "The t-test is always more powerful than the F-test"
      ],
      "correctAnswer": "For k=1, the F-test equals the squared t-test",
      "difficulty": "medium",
      "topic": "Lecture 2 – Hypothesis Testing",
      "explanation": "When $k=1$, $F=t^2$. For $k>1$, use the F-test for joint restrictions."
    },
    {
      "id": "mcq_108",
      "questionText": "Categorical variable with 5 groups. How many dummies do you include to avoid the dummy variable trap (with an intercept)?",
      "options": [
        "5",
        "4",
        "3",
        "2"
      ],
      "correctAnswer": "4",
      "difficulty": "easy",
      "topic": "Lecture 2 – Dummies",
      "explanation": "With an intercept, include $G-1$ dummies to avoid perfect multicollinearity (here $5-1=4$)."
    },
    {
      "id": "mcq_109",
      "questionText": "In Wage = b0 + b1 Female + b2 Educ + b3(Female×Educ) + u, what is the return to education for females?",
      "options": [
        "b2",
        "b2 + b3",
        "b1 + b2",
        "b0 + b2 + b3"
      ],
      "correctAnswer": "b2 + b3",
      "difficulty": "medium",
      "topic": "Lecture 2 – Interactions",
      "explanation": "Female group’s slope on education adds the main effect $b_2$ and interaction $b_3$."
    },
    {
      "id": "mcq_110",
      "questionText": "AIC/BIC are used primarily to:",
      "options": [
        "Test individual coefficients",
        "Balance fit and complexity for model selection",
        "Compute confidence intervals",
        "Detect heteroskedasticity"
      ],
      "correctAnswer": "Balance fit and complexity for model selection",
      "difficulty": "easy",
      "topic": "Lecture 3 – Model Selection",
      "explanation": "They trade off goodness-of-fit (likelihood) against a complexity penalty to avoid overfitting."
    },
    {
      "id": "mcq_111",
      "questionText": "Random walk property: for $X_t = X_{t-1} + u_t$ with $\\operatorname{Var}(u_t)=\\sigma^2$, what is $\\operatorname{Var}(X_t)$ (starting at $X_0=0$)?",
      "options": [
        "$\\sigma^2$",
        "$t\\sigma^2$",
        "$\\sigma^2/t$",
        "$2\\sigma^2$"
      ],
      "correctAnswer": "$t\\sigma^2$",
      "difficulty": "medium",
      "topic": "Lecture 3 – Random Walk Variance",
      "explanation": "$X_t=\\sum_{i=1}^t u_i$ with independent shocks $\\Rightarrow \\operatorname{Var}(X_t)=\\sum \\sigma^2=t\\sigma^2$."
    },
    {
      "id": "mcq_112",
      "questionText": "ACF patterns: which statement is most typical?",
      "options": [
        "AR(1) ACF cuts off after lag 1; MA(1) ACF decays geometrically",
        "AR(1) ACF decays geometrically; MA(1) ACF cuts off after lag 1",
        "Both AR(1) and MA(1) ACF cut off after lag 1",
        "Both AR(1) and MA(1) ACF decay geometrically"
      ],
      "correctAnswer": "AR(1) ACF decays geometrically; MA(1) ACF cuts off after lag 1",
      "difficulty": "medium",
      "topic": "Lecture 3 – ACF Interpretation",
      "explanation": "AR processes show gradually decaying ACF; MA($q$) processes have ACF that becomes zero after lag $q$."
    },
    {
      "id": "mcq_113",
      "questionText": "ADF test on a series including a constant yields p-value = 0.03. Using 5% significance, conclude:",
      "options": [
        "Fail to reject unit root; series is non-stationary",
        "Reject unit root; series is stationary around a constant",
        "Series is explosive",
        "Series is trend-stationary by definition"
      ],
      "correctAnswer": "Reject unit root; series is stationary around a constant",
      "difficulty": "easy",
      "topic": "Lecture 3 – ADF Decision",
      "explanation": "p=0.03<0.05: reject $H_0$ of unit root in the constant-only specification $\\Rightarrow$ stationary around a mean."
    },
    {
      "id": "mcq_114",
      "questionText": "BG test auxiliary regression includes:",
      "options": [
        "Only lagged residuals",
        "Original regressors and lagged residuals",
        "Only the dependent variable and its lag",
        "Only time dummies"
      ],
      "correctAnswer": "Original regressors and lagged residuals",
      "difficulty": "medium",
      "topic": "Lecture 3 – Breusch–Godfrey Procedure",
      "explanation": "Regress $\\hat u_t$ on original $X_t$ and $\\hat u_{t-1},\\ldots,\\hat u_{t-p}$; test joint significance of lagged residuals."
    },
    {
      "id": "mcq_115",
      "questionText": "AR(1): $y_t = c + \\phi y_{t-1} + u_t$ with $|\\phi|<1$. The long-run (unconditional) mean of $y_t$ equals:",
      "options": [
        "0",
        "c",
        "$c / (1 − \\phi)$",
        "$\\phi / (1 − c)$"
      ],
      "correctAnswer": "$c / (1 − \\phi)$",
      "difficulty": "medium",
      "topic": "Lecture 3 – AR(1) Mean",
      "explanation": "At steady state $E(y_t)=E(y_{t-1})=\\mu$: $\\mu=c+\\phi\\mu\\Rightarrow \\mu=\\frac{c}{1-\\phi}$."
    },
    {
      "id": "mcq_116",
      "questionText": "Forecast evaluation: MAPE can be problematic when:",
      "options": [
        "Errors are homoskedastic",
        "Actual values are close to zero",
        "Forecast horizon is short",
        "Data are in logs"
      ],
      "correctAnswer": "Actual values are close to zero",
      "difficulty": "medium",
      "topic": "Lecture 3 – Forecast Metrics",
      "explanation": "MAPE uses $|e_t|/|y_t|$; tiny $|y_t|$ explodes the percentage error, distorting comparisons."
    },
    {
      "id": "mcq_117",
      "questionText": "ARDL intuition: the long-run multiplier divides the sum of X-lag coefficients by:",
      "options": [
        "1 − sum of Y-lag coefficients",
        "Sum of Y-lag coefficients",
        "Variance of residuals",
        "AIC-selected lag order"
      ],
      "correctAnswer": "1 − sum of Y-lag coefficients",
      "difficulty": "medium",
      "topic": "Lecture 3 – ARDL Long-Run",
      "explanation": "LRM $=\\dfrac{\\sum_j \\beta_j}{1-\\sum_i \\phi_i}$; denominator captures persistence from lagged $y$."
    },
    {
      "id": "mcq_118",
      "questionText": "A model’s residual correlogram shows no significant autocorrelation at any lag. This suggests the model is:",
      "options": [
        "Overfit",
        "Dynamically complete (residuals ~ white noise)",
        "Non-stationary",
        "Misspecified in levels"
      ],
      "correctAnswer": "Dynamically complete (residuals ~ white noise)",
      "difficulty": "easy",
      "topic": "Lecture 3 – Model Diagnostics",
      "explanation": "If residuals resemble white noise, the model has extracted systematic dynamics from the series."
    },
    {
      "id": "mcq_119",
      "questionText": "First Differences (FD) vs Fixed Effects (FE): when T=2, which is true?",
      "options": [
        "FD and FE are numerically identical for slope coefficients",
        "FD dominates FE in efficiency",
        "FE dominates FD in efficiency",
        "Neither can be estimated"
      ],
      "correctAnswer": "FD and FE are numerically identical for slope coefficients",
      "difficulty": "medium",
      "topic": "Lecture 4 – FE vs FD",
      "explanation": "With two periods, within-transformation equals differencing, yielding identical slope estimates."
    },
    {
      "id": "mcq_120",
      "questionText": "Including individual and time dummies in a panel regression primarily controls for:",
      "options": [
        "Time-invariant individual heterogeneity and common shocks over time",
        "Only observed covariates",
        "Measurement error",
        "Serial correlation"
      ],
      "correctAnswer": "Time-invariant individual heterogeneity and common shocks over time",
      "difficulty": "easy",
      "topic": "Lecture 4 – Two-Way FE (time dummies)",
      "explanation": "Unit dummies absorb $\\alpha_i$; time dummies absorb common shocks $\\lambda_t$."
    },
    {
      "id": "mcq_121",
      "questionText": "Strict exogeneity fails in FE when the model includes:",
      "options": [
        "Time dummies",
        "Lagged dependent variable",
        "Heteroskedastic errors",
        "Individual dummies"
      ],
      "correctAnswer": "Lagged dependent variable",
      "difficulty": "hard",
      "topic": "Lecture 4 – Exogeneity",
      "explanation": "Including $y_{i,t-1}$ makes $x_{it}$ correlated with future errors (Nickell bias), violating $E(u_{it}|X_i)=0$."
    },
    {
      "id": "mcq_122",
      "questionText": "Unbalanced panels: which statement is correct?",
      "options": [
        "FE cannot be estimated with unbalanced panels",
        "FE can be estimated; observations with missing years are dropped where needed",
        "Unbalanced panels imply inconsistent OLS",
        "Only FD works with unbalanced panels"
      ],
      "correctAnswer": "FE can be estimated; observations with missing years are dropped where needed",
      "difficulty": "medium",
      "topic": "Lecture 4 – Panel Structure",
      "explanation": "FE estimation accommodates differing $T_i$; it uses whatever within variation exists for each unit."
    },
    {
      "id": "mcq_123",
      "questionText": "If residuals in a time-series regression show heteroskedasticity and autocorrelation, a common remedy for inference is to use:",
      "options": [
        "Classical OLS standard errors",
        "HAC/Newey–West standard errors",
        "Cluster by individual",
        "Jackknife standard errors"
      ],
      "correctAnswer": "HAC/Newey–West standard errors",
      "difficulty": "medium",
      "topic": "Lecture 3 – Robust Inference",
      "explanation": "HAC standard errors are consistent under unknown forms of heteroskedasticity and autocorrelation in $u_t$."
    },
    {
      "id": "mcq_124",
      "questionText": "Distributed lag model with $\\beta_0=0.4$ and $\\beta_1=0.3$ ($X_t$ and $X_{t-1}$ only). The long-run (total) multiplier equals:",
      "options": [
        "$0.4$",
        "$0.3$",
        "$0.7$",
        "$1.0$"
      ],
      "correctAnswer": "0.7",
      "difficulty": "easy",
      "topic": "Lecture 3 – DL Multipliers",
      "explanation": "Total effect is the sum of DL coefficients: $0.4+0.3=0.7$."
    },
    {
      "id": "mcq_125",
      "questionText": "ARMA(1,1) one- vs two-step forecasts: which statement is most accurate?",
      "options": [
        "At $h=2$, the MA component still enters via future shocks",
        "At $h=2$, the MA component drops out because future shocks have zero conditional mean",
        "At $h=1$, only the MA component matters",
        "ARMA forecasts revert immediately to the mean at $h=1$"
      ],
      "correctAnswer": "At $h=2$, the MA component drops out because future shocks have zero conditional mean",
      "difficulty": "medium",
      "topic": "Lecture 3 – ARMA Forecasting",
      "explanation": "At horizons $h\\ge2$, unknown future innovations have $E(\\varepsilon_{t+j}|I_t)=0$, so the MA term vanishes; the AR component drives multi-step forecasts."
    }
  ]
}